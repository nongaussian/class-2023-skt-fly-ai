[![License: CC BY-NC-ND 4.0](https://img.shields.io/badge/License-CC%20BY--NC--ND%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-nd/4.0/)

# SKT FLY AI Challenger - Reinforcement Learning

- 김영훈 (한양대학교ERICA 인공지능학과)
- 참조 슬라이드: [Introduction to Reinforcement Learning with David Silver (deepmind.com)](https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver)
 
## Part 1. Introduction to Reinforcement Learning

- [P01-1. Introduction to Reinforcement Learning (pytorch) - upload.pdf](https://www.slideshare.net/secret/1Eo98Cqlw9HdhT)
- [P01-2_backpropagation - upload.pdf](https://www.slideshare.net/secret/5Rj6LZGFgbm08i)<!-- - [P01-3. Building A Practice System - Windows+Miniconda.pdf](https://www.slideshare.net/secret/zFN7xRTmNRBmxs) -->

```python
import torch
from torch.autograd import Variable

x = Variable(
 torch.tensor(1., dtype=torch.float32),
 requires_grad=True)
y = Variable(
 torch.tensor(1., dtype=torch.float32),
 requires_grad=True)
z = Variable(
 torch.tensor(1., dtype=torch.float32),
 requires_grad=True)

optimizer = torch.optim.SGD(params=[x, y, z], lr=0.01)

EPOCHS = 1000
for epoch in range(EPOCHS):
    f = (x + y + z)**2 + (x-1)**2 + (y-1)**2 + (z-1)**2
    optimizer.zero_grad()
    f.backward()
    optimizer.step()
```

- [pytorch-dqn-atari-practice.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269507/pytorch-dqn-atari-practice.ipynb.pdf) 
 [pytorch-dqn-atari-practice.zip](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269606/pytorch-dqn-atari-practice.zip)

## Part 2. Markov Decision Process (Dynamic Programming Approaches)

- [P02. Markov Decision Process - upload.pdf](https://www.slideshare.net/secret/ktUmYma9aVGIDu)
- [example-policy-eval-gridworld.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269509/example-policy-eval-gridworld.ipynb.pdf) [example-policy-eval-gridworld.zip](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269609/example-policy-eval-gridworld.zip)<!-- - [example-policy-eval-pathfinding.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269510/example-policy-eval-pathfinding.ipynb.pdf) [example-policy-eval-pathfinding.zip](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269610/example-policy-eval-pathfinding.zip)-->

## Part 3. Monte-Carlo RL (Bootstrapping Approaches)

- [P03. Monte-Carlo RL - upload.pdf](https://www.slideshare.net/secret/22L8VzdfkxHQ6e)
- [example-mc-black-env.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269241/example-mc-black-env.ipynb.pdf) [example-mc-black-env.zip](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269611/example-mc-black-env.zip)
- [example-mc-on-policy.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269242/example-mc-on-policy.ipynb.pdf) [example-mc-on-policy.zip](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269614/example-mc-on-policy.zip)
- [example-mc-off-policy.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269244/example-mc-off-policy.ipynb.pdf) [example-mc-off-policy.zip](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269613/example-mc-off-policy.zip)


## Part 4. Temporal-Difference RL (Bootstrapping Approaches)

- [P04. Temporal-Difference RL - upload.pdf](https://www.slideshare.net/secret/6UBX0iRcVKEnjW)
- [example-td-sarsa.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269246/example-td-sarsa.ipynb.pdf)
- [example-td-qlearning.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269247/example-td-qlearning.ipynb.pdf)
- [example_td_qlearning_taxi.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269248/example_td_qlearning_taxi.ipynb.pdf)<!-- - [example-td-qlearning-cliffwalking.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269249/example-td-qlearning-cliffwalking.ipynb.pdf) -->

## Part 5. Deep Q-Learning

- [P05. Deep RL (torch) - upload.pdf](https://www.slideshare.net/secret/EDCnQQoVG9T3D1)
- [dqn-shootingairplane-torch.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269251/dqn-shootingairplane-torch.ipynb.pdf) [dqn-shootingairplane-torch-dist.zip](https://github.com/nongaussian/class-2024-skt-fly-ai/files/13830379/dqn-shootingairplane-torch-dist.zip)
- [gym_examples.zip](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269252/gym_examples.zip): shooting airplane  <!-- - [gym_examples(pathfinder).zip](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269253/gym_examples.pathfinder.zip)--> <!-- - [dqn-omok-1-player.ipynb.pdf](https://github.com/nongaussian/class-2023-skt-fly-ai/files/12269256/dqn-omok-1-player.ipynb.pdf) -->

